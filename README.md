# Сервис для pull'инга csv на сервисы-индексаторы
Сервис был написан для одного из клиентов. На github выложен исключительно ради демонстрации моих скиллов в Go.  
Далее следует почти оригинальный README  

## Зачем? 
Выгрузка данных на среды ведется путем обмена csv-файлами.  
Эти файлы нужно забирать с сервера, куда их загружает передающая сторона, и подкладывать сервисам, которые их затем индексируют  
(складывают в БД информацию по остаткам, складам и пр.).  

## Переменные окружения
PullCSV принимает восемь переменных окружения:  
1. DOWNLOAD_FROM (передаётся в манифесте ConfigMap) - строка с полным (вместе с префиксом rsync://USER@SERVER) путём до файлов, которые нужно скачать с сервера.  
Если нужно передать несколько путей, просто разделяем их пробелом.  
Пример: `"rsync://USERNAME@server-name/pullcsv/some-files/*_TODAY_*csv rsync://USERNAME@server-name/pullcsv/some-files2/*_TODAY_*"` 
2. DOWNLOAD_TO (передаётся в манифесте ConfigMap) - строка с полным путём до папки, куда нужно положить скачанные с сервера файлы (откуда их потом заберет сервис-индексатор).  
Если нужно передать несколько путей, просто разделяем их пробелом.  
Пример: `"/path_in_pod/csv/in/ /path_in_pod/stocks/in/"`   
3. RSYNC_PASSWORD (передается в манифесте Secret) - пароль на rsync-сервер. 
4. DOWNLOAD_CRON (опционально передаётся в манифесте ConfigMap) - когда запускать пуллинг файлов.
5. DELETE_CRON (опционально передаётся в манифесте ConfigMap) - когда запускать удаление старых файлов.  
6. DELETE_OLDER_THAN (передаётся в манифесте ConfigMap) - указывается в часах. Pullcsv удалит файлы старше значения, переданного в этой переменной.  
   По умолчанию равна 48.
7. POD_NAME (передаётся в манифесте Deployment) - имя пода, в котором запущен контейнер. 
8. STAND_NAME (передаётся в манифесте Deployment) - имя стенда (namespace), в котором запущен под.  


Все перечисленные переменные, за исключением DOWNLOAD_CRON, DELETE_CRON и DELETE_OLDER_THAN, обязательны!  
При отсутствии какой-либо из них pullcsv упадет, выкинув ошибку с указанием отсутствующей переменной.  
  
Количество путей в DOWNLOAD_FROM должно соответствовать оному в DOWNLOAD_TO,    
DOWNLOAD_CRON и DELETE_CRON - необязательные переменные,  
по умолчанию они принимают значения `"*/10 * * * *"` и `"1 */1 * * *"`, соответственно.  

## На каком языке написан? Какие паттерны использует?
Написан на Go, с использованием Dependency Injection (DI).  
В качестве фреймворка DI выступает Uber fx: [репо на гитхабе](https://github.com/uber-go/fx), [документация](https://uber-go.github.io/fx/)  
Код проекта структурирован по заветам репозитория [golang-standards/project-layout](https://github.com/golang-standards/project-layout)  
Cron реализован силами библиотеки [go-co-op/gocron](https://github.com/go-co-op/gocron)   
При написании функций я старался следовать принципам TDD, где-то это получилось, где-то - нет (но ~85% coverage - уже что-то).   

## Как он работает?
Helicopter view работа PullCSV выглядит так:
1. Uber fx собирает все зависимости, запускает http-сервер на 8080-м порту (он отдает метрики в Prometheus), а затем запускает главную ф-ю - Pullcsv.
2. В Pullcsv стартуют несколько CronJob (зависит от кол-ва путей, переданных в DOWNLOAD_FROM и DOWNLOAD_TO)  
   CronJob бывают двух типов:
     - Для скачивания файлов. Файлы pull'ятся из DOWNLOAD_FROM в DOWNLOAD_TO.  
Сколько передали в env-ах DOWNLOAD_FROM и DOWNLOAD_TO, разделенных пробелами, столько CronJobs будет создано в виде go-рутин.  
Запускаются раз в 10 минут (дефолт), либо по расписанию из DOWNLOAD_CRON.  
     - Для удаления старых файлов. Удаляет все файлы старше DELETE_OLDER_THAN часов во всех DOWNLOAD_TO директориях. Тоже в виде go-рутин.  
Запускаются раз в час (дефолт), либо по расписанию из DELETE_CRON.  

### CronJobs
В CronJob первого типа происходит следующее:
1. Выполняются проверки/преобразования:
   - есть ли rsync в контейнере (или где бы ни был запущен pullcsv)
   - все ли переменные передали и равно ли кол-во путей в DOWNLOAD_FROM и DOWNLOAD_TO
   - "magic" переменные `_TODAY_` и `_YESTERDAY_` в DOWNLOAD_FROM множатся на 2, (становятся `_TODAY_/_TO-DAY_` и `_YESTERDAY_/_YES-TER-DAY_`),  
а затем заменяются на соотв. даты (например, `20240224/2024-02-24` и `20240223/2024-02-23`)   
Сделано это для того, чтобы пуллить файлы не только по маске `*20240224*csv`, но и по `*2024-02-24*csv`.  
   - проверяется наличие exclude файла для флага `--exclude-from=` rsync'а на удаленном сервере, если его нет - создается новый 
2. Запускается скачивание csv файлов.
3. Записываются все метрики для текущего пути из DOWNLOAD_TO.
4. Далее подрезаем exclude файл, если он слишком растолстел и заливаем его на удаленный сервер.
5. Записываем метрики для предыдущего шага. 
6. Если среди csv попались архивы - распаковываем.

CronJob второго типа куда проще, как было сказано выше, — они просто удаляют скачанные в DOWNLOAD_TO файлы старше DELETE_OLDER_THAN часов по расписанию из DELETE_CRON.

## Деплой
Сервис запускается в виде сайдкар-контейнера в поде с контейнером основного сервиса-индексатора.  

## Разработка  
В корне проекта лежит docker-compose.yaml. При необходимости внесения каких-либо изменений:  
 - делаем новую ветку от main
 - вносим нужные изменения 
 - запускаем билд - ```docker compose build```
 - стартуем контейнер - ```docker compose up -d```
 - проверяем (пишите тесты, это правда полезно)
 - сливаем в main
 - делаем новый релиз - создаем tag с описанием новых фичей/багфиксов  

